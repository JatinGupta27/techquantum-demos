{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization for a Simple Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement batch normalization from scratch for a simple neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_forwardprop(Z, gamma, beta, epsilon = 1e-8):\n",
    "    \n",
    "    '''\n",
    "    This function performs batch normalization in a forward propagation on every hidden layer of a neural network. \n",
    "    \n",
    "    Inputs:\n",
    "    Z - the linear output of the layer to be normalized \n",
    "    gamma - the first normalizer parameter\n",
    "    beta - second normalizer parameter\n",
    "    \n",
    "    Output :\n",
    "    Z_out - outputed normalized Z\n",
    "    Cache - a temprorary storage for our prameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Compute the mean of the Zs in the layer\n",
    "    mean = np.mean(Z, axis = 0)\n",
    "    \n",
    "    #compute the variance of the Zs\n",
    "    variance = np.mean((Z - mean)**2)\n",
    "    \n",
    "    #Normalize the Z with mean and standard deviation\n",
    "    Z_norm = (Z - mean) / (np.sqrt(variance + epsilon))\n",
    "    \n",
    "    #Add some noise to the normalized Z so that they are reasonably different\n",
    "    Z_out = (gamma * Z_norm) + beta\n",
    "    \n",
    "    #Store parameters in cache\n",
    "    Cache = (Z, Z_norm, Z_out, mean, variance, gamma, beta)\n",
    "    \n",
    "    return Z_out, Cache\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_backwardprop (Z_out, cache):\n",
    "    \n",
    "    '''\n",
    "    This function performs batch normalization in a forward propagation on every hidden layer of a neural network. \n",
    "    \n",
    "    Inputs:\n",
    "    Z_out - the outputted normalized Z from the forward propagation \n",
    "    Cache - a temprorary storage for our prameters\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    dZ -gradient of Z\n",
    "    dgamma - gradient of gamma\n",
    "    dbeta - gradient of beta\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Retrieve parameters from cache\n",
    "    Z, Z_norm, Z_out, mean, variance, gamma, beta = Cache\n",
    "    \n",
    "    #Retrieve shape of Z\n",
    "    X,Y = Z.shape\n",
    "    \n",
    "    '''\n",
    "    We proceed to calculate the gradients. The formulas for the gradient can be obtained from the original \n",
    "    bactch normalization paper. Or they can be calculated by you, if you are great at calculus. \n",
    "    '''\n",
    "    \n",
    "    Z_mean = Z - mean\n",
    "    inverted_sd = 1. / np.sqrt(var + 1e-8)\n",
    "\n",
    "    dZ_norm = Z_out * gamma\n",
    "    dvar = np.sum(dZ_norm * Z_mu, axis=0) * -.5 * inverted_sd**3\n",
    "    dmean = np.sum(dZ_norm * -inverted_sd, axis=0) + dvar * np.mean(-2. * Z_mean, axis=0)\n",
    "\n",
    "    dZ = (dZ_norm * inverted_sd) + (dvar * 2 * Z_mean / N) + (dmean / N)\n",
    "    dgamma = np.sum(Zout * Z_norm, axis=0)\n",
    "    dbeta = np.sum(Zout, axis=0)\n",
    "\n",
    "    return dZ, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it - Batch normalization implemented from scratch! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
